import os
import requests
import time
from dotenv import load_dotenv
import glob
from lxml import etree
import json

load_dotenv()

NOTION_KEY = os.environ.get("NOTION_KEY")
NOTION_DATABASE_ID = os.environ.get("NOTION_DATABASE_ID")
HEADERS = {
    "Authorization": f"Bearer {NOTION_KEY}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28",
}


# âœ… ì•ˆì „í•œ ë°ì´í„° ì ‘ê·¼ í•¨ìˆ˜
def safe_get(data, keys, default=""):
    """
    ë‹¤ì¤‘ í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ íƒìƒ‰í•˜ì—¬ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    for key in keys:
        if isinstance(data, dict):
            data = data.get(key, {})
        elif isinstance(data, list):
            try:
                data = data[key]
            except (IndexError, TypeError):
                return default
        else:
            return default
    return data if data else default


def paginate_notion_api(url, payload=None):
    """
    Notion APIì˜ í˜ì´ì§€ë„¤ì´ì…˜ì„ ì²˜ë¦¬í•˜ëŠ” ê³µí†µ í•¨ìˆ˜.

    :param url: API í˜¸ì¶œ URL
    :param payload: ìš”ì²­ì— ì‚¬ìš©í•  ì¶”ê°€ ë°ì´í„° (ê¸°ë³¸ê°’: None)
    :return: í˜ì´ì§€ë„¤ì´ì…˜ì„ í†µí•´ ìˆ˜ì§‘ëœ ëª¨ë“  í•­ëª©ì˜ ë¦¬ìŠ¤íŠ¸
    """
    all_results = []
    next_cursor = None  # í˜ì´ì§€ë„¤ì´ì…˜ ì»¤ì„œ

    while True:
        current_payload = payload.copy() if payload else {}
        if next_cursor:
            current_payload["start_cursor"] = next_cursor

        response = requests.post(url, headers=HEADERS, json=current_payload)

        if response.status_code != 200:
            print(f"âŒ Failed to fetch data: {response.json()}")
            break

        data = response.json()
        results = data.get("results", [])
        all_results.extend(results)

        print(f"âœ… Fetched {len(results)} items (Total: {len(all_results)})")

        if data.get("has_more", False):
            next_cursor = data.get("next_cursor")
        else:
            break

    return all_results


# âœ… Notion ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í•­ëª© ê°€ì ¸ì˜¤ê¸° (í˜ì´ì§€ë„¤ì´ì…˜ ì§€ì›)
def fetch_notion_database():
    """
    Notion ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í•­ëª©ì„ ëª¨ë‘ ê°€ì ¸ì™€ old_listë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    url = f"https://api.notion.com/v1/databases/{NOTION_DATABASE_ID}/query"

    results = paginate_notion_api(url)

    old_list = []

    # âœ… resultsì—ì„œ í•­ëª© ì¶”ì¶œ
    for result in results:
        properties = result.get("properties", {})
        item_id = result.get("id", "")
        item_url = safe_get(properties, ["url", "url"], "")
        item_title = safe_get(properties, ["title", "title", 0, "text", "content"], "")
        item_time = safe_get(
            properties, ["time", "rich_text", 0, "text", "content"], ""
        )

        if (
            item_url or item_title
        ):  # and ë¡œ í•˜ ë˜ë©´ ì–´ëŠ í•œìª½ì´ null ì¼ë•ŒëŠ” old_list ì— ë°˜ì˜ì•ˆë¨
            old_list.append(
                {
                    "id": item_id,
                    "url": item_url,
                    "title": item_title,
                    "time": item_time,
                }
            )

    print(f"âœ… Fetched {len(results)} items (Total: {len(old_list)})")

    print(f"âœ… Completed fetching all items from Notion (Total: {len(old_list)})")
    return old_list


# âœ… Notionì— í•­ëª© ì¶”ê°€
def add_to_notion_database(item):
    """
    Notion ë°ì´í„°ë² ì´ìŠ¤ì— í•­ëª©ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    url = "https://api.notion.com/v1/pages"

    payload = {
        "parent": {"database_id": NOTION_DATABASE_ID},
        "properties": {
            "title": {"title": [{"text": {"content": item["title"]}}]},
            "url": {"url": item["url"]},
            "time": {"rich_text": [{"text": {"content": item.get("time", "")}}]},
        },
    }

    response = requests.post(url, headers=HEADERS, json=payload)
    if response.status_code == 200:
        print(f"âœ… Added to Notion: {item['title']}")
    else:
        print(f"âŒ Failed to add to Notion: {item['title']}")
        print(response.json())


# âœ… Notion í•­ëª© ì‚­ì œ
def delete_from_notion_database(item_id):
    """
    Notion ë°ì´í„°ë² ì´ìŠ¤ í•­ëª©ì„ ì‚­ì œí•©ë‹ˆë‹¤.
    """
    url = f"https://api.notion.com/v1/pages/{item_id}"
    payload = {"archived": True}

    response = requests.patch(url, headers=HEADERS, json=payload)
    if response.status_code == 200:
        print(f"âœ… Removed from Notion: {item_id}")
    else:
        print(f"âŒ Failed to remove from Notion: {item_id}")
        print(response.json())


def delete_all_notion_items():
    """
    Notion ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  í•­ëª©ì„ ì œê±°í•©ë‹ˆë‹¤.
    """
    url = f"https://api.notion.com/v1/databases/{NOTION_DATABASE_ID}/query"
    results = paginate_notion_api(url)

    for result in results:
        item_id = result.get("id", "")
        if item_id:
            delete_from_notion_database(item_id)
            time.sleep(0.2)  # API Rate Limit ë°©ì§€ë¥¼ ìœ„í•´ ì ì‹œ ëŒ€ê¸°

    print("âœ… All items in the Notion database have been deleted.")


# âœ… Notion ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
def update_notion_database(added, removed):
    """
    Notion ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    - ì¶”ê°€ëœ í•­ëª©ì€ ì¶”ê°€
    - ì‚­ì œëœ í•­ëª©ì€ ì‚­ì œ
    """
    for item in added:
        add_to_notion_database(item)

    for item in removed:
        delete_from_notion_database(item["id"])


def check_item_exists_in_notion(property_name, value):
    """
    Notion ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ íŠ¹ì • ì†ì„±(property_name)ì˜ ê°’(value)ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

    :param property_name: í•„í„°ë§í•  ì†ì„± ì´ë¦„ (ì˜ˆ: 'URL', 'title')
    :param value: í•„í„°ë§í•  ê°’ (ì˜ˆ: íŠ¹ì • URL, ì œëª©)
    :return: ì¡´ì¬ ì—¬ë¶€ (True/False)
    """
    url = f"https://api.notion.com/v1/databases/{NOTION_DATABASE_ID}/query"

    payload = {
        "filter": {
            "property": property_name,
            property_name.lower(): {"equals": value},  # ì†ì„± íƒ€ì…ì— ë”°ë¼ í•„í„° ì¡°ê±´ ê²°ì •
        }
    }

    response = requests.post(url, headers=HEADERS, json=payload)

    if response.status_code != 200:
        print(f"âŒ Failed to check item existence: {response.json()}")
        return False

    data = response.json()
    results = data.get("results", [])

    if results:
        print(f"âœ… Item exists with {property_name} = {value}")
        return True
    else:
        print(f"âŒ Item does not exist with {property_name} = {value}")
        return False


# âœ… HTML íŒŒì¼ì—ì„œ URLê³¼ ì œëª©ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (XPath ì‚¬ìš©)
def extract_links_from_html(file_path):
    """
    XPathë¥¼ ì‚¬ìš©í•˜ì—¬ HTML íŒŒì¼ì—ì„œ <body> â†’ <section> â†’ <ul> â†’ <li> â†’ <a> êµ¬ì¡°ë¡œ URLê³¼ ì œëª©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    links = []  # ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    # HTML íŒŒì¼ ì½ê¸°
    with open(file_path, "r", encoding="utf-8") as file:
        content = file.read()
        parser = etree.HTMLParser()
        tree = etree.fromstring(content, parser)  # lxmlì„ ì‚¬ìš©í•´ HTML íŒŒì‹±

        # XPathë¥¼ ì‚¬ìš©í•´ a íƒœê·¸ ì°¾ê¸°
        li_tags = tree.xpath("//body/section/ul/li")

        for li in li_tags:
            a_tag = li.xpath('./a[@class="h-cite"]')
            time_tag = li.xpath('./time[@class="dt-published"]')

            url = a_tag[0].get("href") if a_tag else None  # href ì†ì„± ì¶”ì¶œ
            title = (
                a_tag[0].text.strip() if a_tag and a_tag[0].text else None
            )  # íƒœê·¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê³µë°± ì œê±°)
            time = time_tag[0].text.strip() if time_tag and time_tag[0].text else None

            if url and title:
                links.append({"url": url, "title": title, "time": time})

    return links


# âœ… ì—¬ëŸ¬ HTML íŒŒì¼ì—ì„œ URLê³¼ ì œëª©ì„ ì¶”ì¶œ
def process_multiple_html_files(directory, file_pattern="bookmarks-*.html"):
    """
    ì£¼ì–´ì§„ ë””ë ‰í„°ë¦¬ì—ì„œ ì—¬ëŸ¬ HTML íŒŒì¼ì„ ì½ê³  URLê³¼ ì œëª©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    all_links = []  # ëª¨ë“  ë§í¬ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    # íŒŒì¼ íŒ¨í„´ì— ë§ëŠ” ëª¨ë“  HTML íŒŒì¼ ì°¾ê¸°
    file_paths = glob.glob(os.path.join(directory, file_pattern))

    for file_path in file_paths:
        print(f"ğŸ“„ Processing: {file_path}")
        links = extract_links_from_html(file_path)
        all_links.extend(links)  # ì¶”ì¶œëœ ë§í¬ë¥¼ ì „ì²´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€

    with open("all_links.json", "w", encoding="utf-8") as jsonfile:
        json.dump(all_links, jsonfile, indent=2, ensure_ascii=False)

    return all_links


# âœ… ê¸€ë¡œë²Œ ë¹„êµ ë¡œì§
def global_diff_update(old_list, new_list):
    """
    old_list(Notion DB)ì™€ new_list(ë¡œì»¬ ë°ì´í„°)ë¥¼ ë¹„êµí•˜ì—¬ added, removed, unchangedë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.
    """
    old_map = {item["url"]: item for item in old_list}
    new_map = {item["url"]: item for item in new_list}

    added = [item for url, item in new_map.items() if url not in old_map]
    removed = [item for url, item in old_map.items() if url not in new_map]
    unchanged = [item for url, item in new_map.items() if url in old_map]

    print(
        f"âœ… Comparison complete: Added: {len(added)}, Removed: {len(removed)}, Unchanged: {len(unchanged)}"
    )

    return added, removed, unchanged


# âœ… ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    # HTML íŒŒì¼ë“¤ì´ ì €ì¥ëœ ë””ë ‰í„°ë¦¬ ê²½ë¡œ ì„¤ì •
    input_directory = "./bookmarks"

    # âœ… Step 1: Notion ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ old_list ê°€ì ¸ì˜¤ê¸°
    old_list = fetch_notion_database()

    # âœ… Step 2: ë¡œì»¬ HTML íŒŒì¼ì—ì„œ new_list ê°€ì ¸ì˜¤ê¸°
    new_list = process_multiple_html_files(input_directory)
    print(f"âœ… Loaded {len(new_list)} items from bookmarks.")

    # âœ… Step 3: ê¸€ë¡œë²Œ ë¹„êµ ìˆ˜í–‰
    added, removed, unchanged = global_diff_update(old_list, new_list)

    # âœ… Step 4: Notion ì—…ë°ì´íŠ¸ ìˆ˜í–‰
    update_notion_database(added, removed)

    # âœ… check item
    # url_to_check = "https://medium.com/p/building-robust-api-clients-with-refit-rest-library-in-c-43862c4cad76"
    # item_exists = check_item_exists_in_notion("url", url_to_check)
    # if item_exists:
    #     print("âœ… The item already exists in the database.")
    # else:
    #     print("âŒ The item does not exist. You can safely add it.")

    print("\nğŸ¯ Database synchronization complete!")
